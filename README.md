# ğŸ§  YMB AI Bot

A microservice AI assistant designed to generate human-like responses using powerful RAG (Retrieval-Augmented Generation) techniques and Google's **Gemini** AI, deployed on **Google Cloud Run** using Docker.

---

## ğŸš€ Features

- âœ¨ **AI-powered messaging**: Uses **Gemini via ARC** to generate smart, context-aware group messages.
- ğŸ“‚ **Retrieval-Augmented Generation**: Embeds your past messages as context to improve the accuracy and tone of future messages.
- ğŸ³ **Dockerized microservice**: Easily deployable as an isolated container.
- â˜ï¸ **Cloud Run integration**: Automatically deployed with each push to `master`, enabling continuous development.
- ğŸ”„ **Build triggers**: CI/CD enabled via Google Cloud Build for rapid iteration and reliable production deployment.

---

## ğŸ› ï¸ Technology Stack

- **Rust + Axum** backend
- **Tokio** for async runtime
- **Serenity** for Discord/Telegram integrations
- **Google Gemini (via ARC)** for LLM capabilities
- **Custom embedding pipeline** to index and retrieve past messages

---

## ğŸ“ Project Structure

```
ymb-ai-bot/
â”‚
â”œâ”€â”€ src/                # Rust source files
â”‚   â”œâ”€â”€ app.rs          # Axum app entry
â”‚   â”œâ”€â”€ logger.rs       # Tracing + logging setup
â”‚   â””â”€â”€ errors.rs       # Error handling
â”‚
â”œâ”€â”€ config/             # Environment-specific configs
â”œâ”€â”€ documents/          # Text files for embedding into RAG pipeline
â”œâ”€â”€ Dockerfile          # For containerization
â”œâ”€â”€ compose.yaml        # (optional) Docker Compose setup
â”œâ”€â”€ Cargo.toml          # Rust dependencies
â””â”€â”€ README.md
```

---

## â˜ï¸ Deployment (Google Cloud Run)

This project is deployed using **Google Cloud Run**:

- âœ… Containerized using the provided `Dockerfile`
- ğŸ”„ Deployed using **Cloud Build triggers** with every push to the `master` branch
- ğŸ§ª Enables **continuous development** and quick feedback loops

### Sample Build Trigger Config (GCP):

- **Trigger Source**: GitHub repo
- **Branch**: `master`
- **Build Config**: Dockerfile
- **Deploy To**: Cloud Run service

---

## ğŸ§  AI Integration (Gemini + ARC)

This bot is enhanced with **AI Agent capabilities** via Googleâ€™s **Gemini API** through ARC:

- ğŸ“„ **Past messages** are embedded as vector representations
- ğŸ§  These embeddings are used during inference to **retrieve relevant past contexts**
- ğŸ’¬ The model can then **generate personalized, relevant responses** that feel consistent with past human-written messages

---

## ğŸ“¦ Running Locally

```bash
# Build and run using Docker
docker build -t ymb-ai-bot .
docker run -p 8080:8080 ymb-ai-bot
```

---
